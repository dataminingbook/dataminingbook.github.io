<div id="pf258" class="pf w0 h0" data-page-no="258"><div class="pc pc258 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg258.png"/><div class="t m0 x1c hc y2f ff9 fs0 fc0 sc0 ls0 ws0">588<span class="_ _e"> </span><span class="ff2">Classificatio<span class="_ _9"></span>n<span class="_ _6"> </span>Assess<span class="_ _9"></span>ment</span></div><div class="t m0 x1c h4 y30 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _a"> </span>derivativ<span class="_ _2"></span>e<span class="_ _6"> </span>of<span class="_ _a"> </span>the<span class="_ _a"> </span>error<span class="_ _a"> </span>f<span class="_ _2"></span>unction<span class="_ _6"> </span>with<span class="_ _4"> </span>respect<span class="_ _a"> </span>to<span class="_ _a"> </span>the<span class="_ _a"> </span>net<span class="_ _a"> </span>input<span class="_ _a"> </span>at<span class="_ _a"> </span>a<span class="_ _4"> </span>layer<span class="_ _6"> </span>—<span class="_ _4"> </span>the<span class="_ _6"> </span><span class="ff4">net</span></div><div class="t m0 x1c h4 y31 ff4 fs2 fc0 sc0 ls0 ws0">gradient<span class="_ _5"> </span><span class="ff3">vec<span class="_ _2"></span>tor.<span class="_ _5"> </span>We<span class="_ _5"> </span>show<span class="_ _5"> </span>how<span class="_ _6"> </span>during<span class="_ _5"> </span>le<span class="_ _2"></span>arning<span class="_ _5"> </span>the<span class="_ _5"> </span>error<span class="_ _6"> </span>propagates<span class="_ _5"> </span>from<span class="_ _5"> </span>t<span class="_ _2"></span>he<span class="_ _5"> </span>output<span class="_ _5"> </span>to</span></div><div class="t m0 x1c h4 y32 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _8"> </span>hidden,<span class="_ _5"> </span>and<span class="_ _5"> </span>then<span class="_ _5"> </span>from<span class="_ _8"> </span>the<span class="_ _5"> </span>hidden<span class="_ _8"> </span>t<span class="_ _2"></span>o<span class="_ _8"> </span>the<span class="_ _5"> </span>input<span class="_ _8"> </span>la<span class="_ _2"></span>yer<span class="_ _8"> </span>of<span class="_ _5"> </span>neurons.<span class="_ _5"> </span>Next,<span class="_ _8"> </span>we<span class="_ _5"> </span>generalize</div><div class="t m0 x1c h4 y33 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _6"> </span>model<span class="_ _6"> </span>to<span class="_ _6"> </span>deep<span class="_ _5"> </span>MLPs<span class="_ _6"> </span>t<span class="_ _2"></span>hat<span class="_ _5"> </span>comprise<span class="_ _6"> </span>many<span class="_ _6"> </span>hidden<span class="_ _6"> </span>layers<span class="_ _6"> </span>of<span class="_ _6"> </span>neurons.<span class="_ _6"> </span>We<span class="_ _5"> </span>show<span class="_ _a"> </span>how</div><div class="t m0 x1c h4 y34 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _5"> </span>net<span class="_"> </span>w<span class="_"> </span>ork<span class="_ _6"> </span>is<span class="_ _5"> </span>tra<span class="_ _2"></span>ined<span class="_ _5"> </span>using<span class="_ _5"> </span>the<span class="_ _6"> </span>same<span class="_ _5"> </span>g<span class="_ _2"></span>eneral<span class="_ _5"> </span>backpropagation<span class="_ _5"> </span>approach<span class="_ _6"> </span>based<span class="_ _5"> </span>on<span class="_ _6"> </span>the</div><div class="t m0 x1c h4 y35 ff3 fs2 fc0 sc0 ls0 ws0">net<span class="_ _6"> </span>gradients.</div><div class="t m0 x1d h4 y36 ff3 fs2 fc0 sc0 ls0 ws0">In<span class="_ _d"> </span>Chapter<span class="_ _d"> </span>26,<span class="_ _d"> </span>we<span class="_ _d"> </span>discuss<span class="_ _d"> </span>the<span class="_ _d"> </span>details<span class="_ _d"> </span>of<span class="_ _d"> </span>ke<span class="_ _2"></span>y<span class="_ _b"> </span>deep<span class="_ _d"> </span>learning<span class="_ _d"> </span>models<span class="_ _d"> </span>in<span class="_ _d"> </span>deta<span class="_ _2"></span>il,</div><div class="t m0 x1c h4 y37 ff3 fs2 fc0 sc0 ls0 ws0">namely<span class="_ _c"> </span>recurrent<span class="_ _f"> </span>neural<span class="_ _c"> </span>net<span class="_ _2"></span>works<span class="_ _c"> </span>(RNNs),<span class="_ _c"> </span>Long<span class="_ _f"> </span>Short-term<span class="_ _c"> </span>Me<span class="_"> </span>mory<span class="_ _f"> </span>Ne<span class="_"> </span>t<span class="_ _2"></span>works</div><div class="t m0 x1c h4 y38 ff3 fs2 fc0 sc0 ls0 ws0">(LSTMs)<span class="_ _9"></span>,<span class="_ _6"> </span>and<span class="_ _6"> </span>convolutional<span class="_ _6"> </span>neural<span class="_ _5"> </span>networks<span class="_ _6"> </span>(CNNs).<span class="_ _6"> </span>Recurrent<span class="_ _5"> </span>ne<span class="_ _2"></span>tworks<span class="_ _5"> </span>gene<span class="_"> </span>ra<span class="_ _2"></span>lize</div><div class="t m0 x1c h4 y39 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _6"> </span>feed-forward<span class="_ _5"> </span>architect<span class="_ _2"></span>ure<span class="_ _5"> </span>of<span class="_ _6"> </span>ML<span class="_ _9"></span>Ps<span class="_ _6"> </span>by<span class="_ _5"> </span>introducing<span class="_ _6"> </span>feed-ba<span class="_ _2"></span>ck<span class="_ _5"> </span>connections<span class="_ _5"> </span>be<span class="_ _2"></span>tween</div><div class="t m0 x1c h4 y3a ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _10"> </span>layers<span class="_ _10"> </span>to<span class="_ _10"> </span>model<span class="_ _10"> </span>sequential<span class="_ _10"> </span>data<span class="_ _2"></span>.<span class="_ _f"> </span>We<span class="_ _10"> </span>show<span class="_ _10"> </span>how<span class="_ _10"> </span>R<span class="_"> </span>N<span class="_ _2"></span>Ns<span class="_ _f"> </span>can<span class="_ _10"> </span>be<span class="_ _11"> </span>trained<span class="_ _10"> </span>via</div><div class="t m0 x1c h4 y3b ff4 fs2 fc0 sc0 ls0 ws0">backpropagation<span class="_ _4"> </span>in<span class="_ _4"> </span>time<span class="ff3">,<span class="_ _4"> </span>which<span class="_ _4"> </span>is<span class="_ _4"> </span>essentially<span class="_ _4"> </span>the<span class="_ _4"> </span>same<span class="_ _4"> </span>as<span class="_ _4"> </span>the<span class="_ _4"> </span>MLP<span class="_ _4"> </span>backpropagation</span></div><div class="t m0 x1c h4 y3c ff3 fs2 fc0 sc0 ls0 ws0">approach<span class="_ _5"> </span>applied<span class="_ _5"> </span>t<span class="_ _2"></span>o<span class="_ _5"> </span>the<span class="_ _5"> </span>R<span class="_ _2"></span>NN<span class="_ _5"> </span>unfolded<span class="_ _5"> </span>in<span class="_ _5"> </span>time<span class="_ _6"> </span>so<span class="_ _5"> </span>that<span class="_ _5"> </span>it<span class="_ _6"> </span>becomes<span class="_ _5"> </span>a<span class="_ _6"> </span>deep<span class="_ _5"> </span>feed-forward</div><div class="t m0 x1c h4 y3d ff3 fs2 fc0 sc0 ls0 ws0">network.<span class="_ _4"> </span>We<span class="_ _4"> </span>highlight<span class="_ _4"> </span>the<span class="_ _4"> </span>concepts<span class="_ _4"> </span>of<span class="_ _4"> </span><span class="ff4">shared<span class="_ _4"> </span>parameters</span>,<span class="_ _4"> </span>since<span class="_ _4"> </span>RNNs<span class="_ _4"> </span>use<span class="_ _4"> </span>the<span class="_ _4"> </span>same</div><div class="t m0 x1c h4 y3e ff3 fs2 fc0 sc0 ls0 ws0">weight<span class="_ _6"> </span>matrix<span class="_ _6"> </span>and<span class="_ _6"> </span>bias<span class="_ _6"> </span>ve<span class="_ _2"></span>ctor<span class="_ _5"> </span>for<span class="_ _a"> </span>the<span class="_ _6"> </span>hidden<span class="_ _6"> </span>layers<span class="_ _6"> </span>for<span class="_ _6"> </span>all<span class="_ _6"> </span>time<span class="_ _6"> </span>points.<span class="_ _a"> </span>Unfortunately,</div><div class="t m0 x1c h4 y3f ff3 fs2 fc0 sc0 ls0 ws0">deep<span class="_ _3"> </span>RNNs<span class="_ _3"> </span>are<span class="_ _3"> </span>susceptible<span class="_ _3"> </span>to<span class="_ _3"> </span>t<span class="_ _2"></span>he<span class="_ _4"> </span>problem<span class="_ _1"> </span>of<span class="_ _4"> </span><span class="ff4">v<span class="_ _2"></span>anishing<span class="_ _4"> </span></span>or<span class="_ _1"> </span><span class="ff4">exploding<span class="_ _4"> </span></span>net<span class="_ _1"> </span>gradients</div><div class="t m0 x1c h4 y40 ff3 fs2 fc0 sc0 ls0 ws0">during<span class="_ _6"> </span>backpropagation.<span class="_ _6"> </span>Lon<span class="_ _9"></span>g<span class="_ _6"> </span>short-term<span class="_ _6"> </span>memory<span class="_ _6"> </span>networks<span class="_ _6"> </span>alleviate<span class="_ _5"> </span>this<span class="_ _6"> </span>problem<span class="_ _6"> </span>by</div><div class="t m0 x1c h4 y41 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _5"> </span>use<span class="_ _5"> </span>of<span class="_ _5"> </span>a<span class="_ _5"> </span>novel<span class="_ _5"> </span>type<span class="_ _5"> </span>of<span class="_ _5"> </span>layer,<span class="_ _5"> </span>called<span class="_ _5"> </span>a<span class="_ _5"> </span><span class="ff4">gated<span class="_ _5"> </span>layer</span>,<span class="_ _5"> </span>to<span class="_ _5"> </span>control<span class="_ _5"> </span>what<span class="_ _5"> </span>information<span class="_ _5"> </span>is<span class="_ _5"> </span>used</div><div class="t m0 x1c h4 y42 ff3 fs2 fc0 sc0 ls0 ws0">to<span class="_ _a"> </span>input,<span class="_ _a"> </span>update,<span class="_ _a"> </span>and<span class="_ _a"> </span>write<span class="_ _a"> </span>an<span class="_ _a"> </span>inte<span class="_ _2"></span>rnal<span class="_ _6"> </span>memory<span class="_ _4"> </span>layer.<span class="_ _6"> </span>N<span class="_ _2"></span>ext,<span class="_ _a"> </span>we<span class="_ _a"> </span>discuss<span class="_ _a"> </span>convolutional</div><div class="t m0 x1c h4 y43 ff3 fs2 fc0 sc0 ls0 ws0">neural<span class="_ _b"> </span>net<span class="_ _2"></span>works<span class="_ _b"> </span>that<span class="_ _d"> </span>are<span class="_ _b"> </span>e<span class="_ _2"></span>ssentially<span class="_ _b"> </span>deep<span class="_ _d"> </span>and<span class="_ _d"> </span>sparse<span class="_ _d"> </span>MLPs<span class="_ _d"> </span>that<span class="_ _d"> </span>are<span class="_ _d"> </span>designed<span class="_ _d"> </span>to</div><div class="t m0 x1c h4 y44 ff3 fs2 fc0 sc0 ls0 ws0">hierarchically<span class="_ _6"> </span>e<span class="_ _2"></span>xploit<span class="_ _6"> </span>se<span class="_"> </span>que<span class="_ _2"></span>ntial<span class="_ _6"> </span>and<span class="_ _a"> </span>spatial<span class="_ _a"> </span>relationships<span class="_ _a"> </span>in<span class="_ _a"> </span>the<span class="_ _a"> </span>data.<span class="_ _a"> </span>Finally,<span class="_ _a"> </span>we<span class="_ _a"> </span>also</div><div class="t m0 x1c h4 y45 ff3 fs2 fc0 sc0 ls0 ws0">discuss<span class="_ _1"> </span>the<span class="_ _3"> </span>role<span class="_ _1"> </span>of<span class="_ _1"> </span>regularization<span class="_ _3"> </span>in<span class="_ _1"> </span>deep<span class="_ _1"> </span>learning,<span class="_ _3"> </span>including<span class="_ _1"> </span><span class="ff4">L</span></div><div class="t m0 x1e h5 y46 ff3 fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1f h4 y45 ff3 fs2 fc0 sc0 ls0 ws0">regularization<span class="_ _1"> </span>and</div><div class="t m0 x1c h4 y47 ff4 fs2 fc0 sc0 ls0 ws0">dropout<span class="_ _6"> </span>regularization<span class="ff3">.</span></div><div class="t m0 x1d h4 y48 ff3 fs2 fc0 sc0 ls0 ws0">We<span class="_ _5"> </span>end<span class="_ _5"> </span>this<span class="_ _5"> </span>part<span class="_ _6"> </span>with<span class="_ _5"> </span>methods<span class="_ _5"> </span>to<span class="_ _5"> </span>ev<span class="_ _2"></span>aluate<span class="_ _8"> </span>reg<span class="_ _2"></span>ression<span class="_ _8"> </span>models<span class="_ _6"> </span>in<span class="_ _5"> </span>Chapter<span class="_ _5"> </span>27,<span class="_ _5"> </span>with<span class="_ _5"> </span>a</div><div class="t m0 x1c h4 y49 ff3 fs2 fc0 sc0 ls0 ws0">focus<span class="_ _5"> </span>on<span class="_ _6"> </span>linear<span class="_ _6"> </span>regression.<span class="_ _5"> </span>We<span class="_ _6"> </span>consider<span class="_ _6"> </span>the<span class="_ _5"> </span>questions<span class="_ _6"> </span>of<span class="_ _6"> </span>how<span class="_ _5"> </span>good<span class="_ _6"> </span>of<span class="_ _6"> </span>a<span class="_ _5"> </span>ﬁt<span class="_ _6"> </span>is<span class="_ _6"> </span>the<span class="_ _5"> </span>model</div><div class="t m0 x1c h4 y4a ff3 fs2 fc0 sc0 ls0 ws0">to<span class="_ _5"> </span>the<span class="_ _6"> </span>input<span class="_ _5"> </span>data,<span class="_ _5"> </span>and<span class="_ _6"> </span>how<span class="_ _5"> </span>one<span class="_ _5"> </span>can<span class="_ _5"> </span>de<span class="_ _2"></span>rive<span class="_ _5"> </span>conﬁdence<span class="_ _5"> </span>intervals<span class="_ _5"> </span>a<span class="_ _2"></span>nd<span class="_ _5"> </span>perform<span class="_ _5"> </span>hypothesis</div><div class="t m0 x1c h4 y4b ff3 fs2 fc0 sc0 ls0 ws0">tests<span class="_ _4"> </span>for<span class="_ _4"> </span>the<span class="_ _4"> </span>dependence<span class="_ _4"> </span>of<span class="_ _4"> </span>the<span class="_ _4"> </span>response<span class="_ _4"> </span>variable<span class="_ _4"> </span>on<span class="_ _4"> </span>the<span class="_ _4"> </span>independent<span class="_ _4"> </span>variables.<span class="_ _a"> </span>We</div><div class="t m0 x1c h4 y4c ff3 fs2 fc0 sc0 ls0 ws0">especially<span class="_ _6"> </span>emphasize<span class="_ _5"> </span>the<span class="_ _6"> </span>geometric<span class="_ _6"> </span>approach<span class="_ _5"> </span>to<span class="_ _6"> </span>evaluation.</div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
