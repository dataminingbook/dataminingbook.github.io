<div id="pf258" class="pf w0 h0" data-page-no="258"><div class="pc pc258 w0 h0"><img class="bi x0 y0 w1 h1" alt="" src="bg258.png"/><div class="t m0 x21 h10 y35 ffa fs0 fc0 sc0 ls0 ws0">588<span class="_ _e"> </span><span class="ff2">Classificatio<span class="_ _9"></span>n<span class="_ _6"> </span>Assess<span class="_ _9"></span>ment</span></div><div class="t m0 x21 h4 y36 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _a"> </span>derivativ<span class="_ _2"></span>e<span class="_ _6"> </span>of<span class="_ _a"> </span>the<span class="_ _a"> </span>error<span class="_ _a"> </span>funct<span class="_ _2"></span>ion<span class="_ _6"> </span>with<span class="_ _a"> </span>re<span class="_ _2"></span>spect<span class="_ _6"> </span>t<span class="_ _2"></span>o<span class="_ _6"> </span>the<span class="_ _a"> </span>ne<span class="_ _2"></span>t<span class="_ _6"> </span>input<span class="_ _4"> </span>at<span class="_ _a"> </span>a<span class="_ _a"> </span>layer<span class="_ _a"> </span>—<span class="_ _a"> </span>the<span class="_ _a"> </span><span class="ff4">net</span></div><div class="t m0 x21 h4 y37 ff4 fs2 fc0 sc0 ls0 ws0">gradient<span class="_ _5"> </span><span class="ff3">vec<span class="_ _2"></span>tor.<span class="_ _5"> </span>We<span class="_ _5"> </span>show<span class="_ _5"> </span>how<span class="_ _6"> </span>during<span class="_ _5"> </span>le<span class="_ _2"></span>arning<span class="_ _5"> </span>the<span class="_ _5"> </span>error<span class="_ _6"> </span>propagates<span class="_ _5"> </span>from<span class="_ _5"> </span>t<span class="_ _2"></span>he<span class="_ _5"> </span>output<span class="_ _5"> </span>to</span></div><div class="t m0 x21 h4 y38 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _8"> </span>hidden,<span class="_ _5"> </span>and<span class="_ _5"> </span>then<span class="_ _5"> </span>from<span class="_ _8"> </span>the<span class="_ _5"> </span>hidden<span class="_ _8"> </span>t<span class="_ _2"></span>o<span class="_ _8"> </span>the<span class="_ _5"> </span>input<span class="_ _8"> </span>la<span class="_ _2"></span>yer<span class="_ _8"> </span>of<span class="_ _5"> </span>neurons.<span class="_ _5"> </span>Next,<span class="_ _8"> </span>we<span class="_ _5"> </span>generalize</div><div class="t m0 x21 h4 y39 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _6"> </span>model<span class="_ _6"> </span>to<span class="_ _6"> </span>deep<span class="_ _5"> </span>MLPs<span class="_ _6"> </span>t<span class="_ _2"></span>hat<span class="_ _5"> </span>comprise<span class="_ _6"> </span>many<span class="_ _6"> </span>hidden<span class="_ _6"> </span>layers<span class="_ _6"> </span>of<span class="_ _6"> </span>neurons.<span class="_ _6"> </span>We<span class="_ _6"> </span>sh<span class="_ _9"></span>ow<span class="_ _6"> </span>how</div><div class="t m0 x21 h4 y3a ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _5"> </span>net<span class="_"> </span>w<span class="_"> </span>ork<span class="_ _6"> </span>is<span class="_ _5"> </span>tra<span class="_ _2"></span>ined<span class="_ _5"> </span>using<span class="_ _5"> </span>the<span class="_ _6"> </span>same<span class="_ _5"> </span>g<span class="_ _2"></span>eneral<span class="_ _5"> </span>backpropagation<span class="_ _5"> </span>approach<span class="_ _6"> </span>based<span class="_ _5"> </span>on<span class="_ _6"> </span>the</div><div class="t m0 x21 h4 y3b ff3 fs2 fc0 sc0 ls0 ws0">net<span class="_ _6"> </span>gradients.</div><div class="t m0 x22 h4 y3c ff3 fs2 fc0 sc0 ls0 ws0">In<span class="_ _d"> </span>Chapter<span class="_ _d"> </span>26,<span class="_ _d"> </span>we<span class="_ _d"> </span>discuss<span class="_ _d"> </span>t<span class="_"> </span>he<span class="_ _d"> </span>det<span class="_ _2"></span>ails<span class="_ _b"> </span>of<span class="_ _d"> </span>key<span class="_ _d"> </span>deep<span class="_ _d"> </span>le<span class="_ _2"></span>arning<span class="_ _b"> </span>models<span class="_ _d"> </span>in<span class="_ _d"> </span>deta<span class="_ _2"></span>il,</div><div class="t m0 x21 h4 y3d ff3 fs2 fc0 sc0 ls0 ws0">namely<span class="_ _c"> </span>recurrent<span class="_ _f"> </span>neural<span class="_ _c"> </span>networks<span class="_ _f"> </span>(RN<span class="_ _2"></span>Ns),<span class="_ _f"> </span>Long<span class="_ _f"> </span>Short-t<span class="_ _2"></span>erm<span class="_ _f"> </span>Memory<span class="_ _c"> </span>Networks</div><div class="t m0 x21 h4 y3e ff3 fs2 fc0 sc0 ls0 ws0">(LSTMs)<span class="_ _9"></span>,<span class="_ _6"> </span>and<span class="_ _6"> </span>convolutional<span class="_ _6"> </span>neural<span class="_ _5"> </span>netw<span class="_"> </span>orks<span class="_ _6"> </span>(CNNs).<span class="_ _6"> </span>Recurrent<span class="_ _5"> </span>ne<span class="_"> </span>t<span class="_ _2"></span>works<span class="_ _5"> </span>genera<span class="_ _2"></span>lize</div><div class="t m0 x21 h4 y3f ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _6"> </span>feed-forward<span class="_ _5"> </span>architect<span class="_ _2"></span>ure<span class="_ _5"> </span>of<span class="_ _6"> </span>ML<span class="_ _9"></span>Ps<span class="_ _6"> </span>by<span class="_ _5"> </span>introducing<span class="_ _6"> </span>feed-ba<span class="_ _2"></span>ck<span class="_ _5"> </span>connections<span class="_ _6"> </span>between</div><div class="t m0 x21 h4 y40 ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _10"> </span>layers<span class="_ _10"> </span>to<span class="_ _10"> </span>model<span class="_ _10"> </span>sequential<span class="_ _10"> </span>data<span class="_ _2"></span>.<span class="_ _c"> </span>We<span class="_ _10"> </span>show<span class="_ _10"> </span>how<span class="_ _10"> </span>RNN<span class="_"> </span>s<span class="_ _10"> </span>can<span class="_ _10"> </span>be<span class="_ _11"> </span>trained<span class="_ _c"> </span>v<span class="_ _2"></span>ia</div><div class="t m0 x21 h4 y3 ff4 fs2 fc0 sc0 ls0 ws0">backpropagation<span class="_ _4"> </span>in<span class="_ _4"> </span>time<span class="ff3">,<span class="_ _4"> </span>which<span class="_ _4"> </span>is<span class="_ _4"> </span>essentially<span class="_ _4"> </span>the<span class="_ _4"> </span>same<span class="_ _4"> </span>as<span class="_ _4"> </span>the<span class="_ _4"> </span>MLP<span class="_ _4"> </span>backpropagation</span></div><div class="t m0 x21 h4 y4 ff3 fs2 fc0 sc0 ls0 ws0">approach<span class="_ _5"> </span>applied<span class="_ _5"> </span>t<span class="_ _2"></span>o<span class="_ _5"> </span>the<span class="_ _5"> </span>R<span class="_ _2"></span>NN<span class="_ _5"> </span>unfolded<span class="_ _5"> </span>in<span class="_ _5"> </span>time<span class="_ _6"> </span>so<span class="_ _5"> </span>that<span class="_ _5"> </span>it<span class="_ _6"> </span>becomes<span class="_ _5"> </span>a<span class="_ _6"> </span>deep<span class="_ _5"> </span>feed-forward</div><div class="t m0 x21 h4 y6 ff3 fs2 fc0 sc0 ls0 ws0">network.<span class="_ _4"> </span>We<span class="_ _4"> </span>highlight<span class="_ _4"> </span>the<span class="_ _4"> </span>concepts<span class="_ _4"> </span>of<span class="_ _4"> </span><span class="ff4">shared<span class="_ _4"> </span>parameters</span>,<span class="_ _4"> </span>since<span class="_ _4"> </span>RNNs<span class="_ _4"> </span>use<span class="_ _4"> </span>the<span class="_ _4"> </span>same</div><div class="t m0 x21 h4 y7 ff3 fs2 fc0 sc0 ls0 ws0">weight<span class="_ _6"> </span>matrix<span class="_ _6"> </span>and<span class="_ _6"> </span>bias<span class="_ _6"> </span>v<span class="_"> </span>e<span class="_ _2"></span>ctor<span class="_ _5"> </span>for<span class="_ _a"> </span>the<span class="_ _6"> </span>hidden<span class="_ _6"> </span>layers<span class="_ _6"> </span>for<span class="_ _6"> </span>all<span class="_ _6"> </span>time<span class="_ _6"> </span>points.<span class="_ _a"> </span>Unfortunately,</div><div class="t m0 x21 h4 y8 ff3 fs2 fc0 sc0 ls0 ws0">deep<span class="_ _3"> </span>RNNs<span class="_ _3"> </span>are<span class="_ _3"> </span>susceptible<span class="_ _3"> </span>to<span class="_ _3"> </span>t<span class="_ _2"></span>he<span class="_ _4"> </span>problem<span class="_ _1"> </span>of<span class="_ _4"> </span><span class="ff4">v<span class="_"> </span>a<span class="_ _2"></span>nishing<span class="_ _4"> </span></span>or<span class="_ _3"> </span><span class="ff4">e<span class="_ _2"></span>xploding<span class="_ _4"> </span></span>ne<span class="_"> </span>t<span class="_ _1"> </span>gradients</div><div class="t m0 x21 h4 y9 ff3 fs2 fc0 sc0 ls0 ws0">during<span class="_ _6"> </span>backpropagation.<span class="_ _6"> </span>Lon<span class="_ _9"></span>g<span class="_ _6"> </span>short-term<span class="_ _6"> </span>memory<span class="_ _6"> </span>networks<span class="_ _6"> </span>alleviate<span class="_ _5"> </span>this<span class="_ _6"> </span>problem<span class="_ _6"> </span>by</div><div class="t m0 x21 h4 yb ff3 fs2 fc0 sc0 ls0 ws0">the<span class="_ _5"> </span>use<span class="_ _5"> </span>of<span class="_ _5"> </span>a<span class="_ _5"> </span>novel<span class="_ _5"> </span>type<span class="_ _5"> </span>of<span class="_ _5"> </span>layer,<span class="_ _5"> </span>called<span class="_ _5"> </span>a<span class="_ _5"> </span><span class="ff4">gated<span class="_ _5"> </span>layer</span>,<span class="_ _5"> </span>to<span class="_ _5"> </span>control<span class="_ _5"> </span>what<span class="_ _5"> </span>information<span class="_ _5"> </span>is<span class="_ _5"> </span>used</div><div class="t m0 x21 h4 yd ff3 fs2 fc0 sc0 ls0 ws0">to<span class="_ _a"> </span>input,<span class="_ _a"> </span>update,<span class="_ _a"> </span>and<span class="_ _a"> </span>write<span class="_ _a"> </span>an<span class="_ _a"> </span>internal<span class="_ _a"> </span>memory<span class="_ _4"> </span>layer.<span class="_ _a"> </span>Next,<span class="_ _a"> </span>we<span class="_ _a"> </span>discuss<span class="_ _a"> </span>convolutional</div><div class="t m0 x21 h4 ye ff3 fs2 fc0 sc0 ls0 ws0">neural<span class="_ _b"> </span>net<span class="_ _2"></span>works<span class="_ _b"> </span>that<span class="_ _d"> </span>are<span class="_ _d"> </span>essentially<span class="_ _d"> </span>deep<span class="_ _d"> </span>and<span class="_ _d"> </span>sparse<span class="_ _d"> </span>MLPs<span class="_ _d"> </span>that<span class="_ _d"> </span>are<span class="_ _d"> </span>designed<span class="_ _d"> </span>to</div><div class="t m0 x21 h4 yf ff3 fs2 fc0 sc0 ls0 ws0">hierarchically<span class="_ _6"> </span>e<span class="_ _2"></span>xploit<span class="_ _6"> </span>se<span class="_ _2"></span>quential<span class="_ _6"> </span>and<span class="_ _a"> </span>spatial<span class="_ _a"> </span>relationships<span class="_ _a"> </span>in<span class="_ _a"> </span>the<span class="_ _a"> </span>data.<span class="_ _a"> </span>Finally,<span class="_ _a"> </span>we<span class="_ _6"> </span>a<span class="_ _2"></span>lso</div><div class="t m0 x21 h4 y11 ff3 fs2 fc0 sc0 ls0 ws0">discuss<span class="_ _1"> </span>the<span class="_ _3"> </span>role<span class="_ _1"> </span>of<span class="_ _1"> </span>regularization<span class="_ _3"> </span>in<span class="_ _1"> </span>deep<span class="_ _1"> </span>learning,<span class="_ _3"> </span>including<span class="_ _1"> </span><span class="ff4">L</span></div><div class="t m0 x23 h5 y12 ff3 fs3 fc0 sc0 ls0 ws0">2</div><div class="t m0 x24 h4 y11 ff3 fs2 fc0 sc0 ls0 ws0">regularization<span class="_ _1"> </span>and</div><div class="t m0 x21 h4 y13 ff4 fs2 fc0 sc0 ls0 ws0">dropout<span class="_ _6"> </span>regularization<span class="ff3">.</span></div><div class="t m0 x22 h4 y14 ff3 fs2 fc0 sc0 ls0 ws0">We<span class="_ _5"> </span>end<span class="_ _5"> </span>this<span class="_ _5"> </span>pa<span class="_"> </span>rt<span class="_ _6"> </span>with<span class="_ _5"> </span>methods<span class="_ _5"> </span>to<span class="_ _5"> </span>ev<span class="_ _2"></span>aluate<span class="_ _8"> </span>reg<span class="_ _2"></span>ression<span class="_ _8"> </span>models<span class="_ _6"> </span>in<span class="_ _5"> </span>Chapter<span class="_ _5"> </span>27,<span class="_ _5"> </span>with<span class="_ _5"> </span>a</div><div class="t m0 x21 h4 y15 ff3 fs2 fc0 sc0 ls0 ws0">focus<span class="_ _5"> </span>on<span class="_ _6"> </span>linear<span class="_ _6"> </span>regression.<span class="_ _5"> </span>We<span class="_ _6"> </span>consider<span class="_ _6"> </span>the<span class="_ _5"> </span>questions<span class="_ _6"> </span>of<span class="_ _6"> </span>how<span class="_ _5"> </span>good<span class="_ _6"> </span>of<span class="_ _6"> </span>a<span class="_ _5"> </span>ﬁt<span class="_ _6"> </span>is<span class="_ _6"> </span>the<span class="_ _5"> </span>model</div><div class="t m0 x21 h4 y17 ff3 fs2 fc0 sc0 ls0 ws0">to<span class="_ _5"> </span>the<span class="_ _6"> </span>input<span class="_ _5"> </span>data,<span class="_ _5"> </span>and<span class="_ _6"> </span>how<span class="_ _5"> </span>one<span class="_ _5"> </span>can<span class="_ _5"> </span>de<span class="_ _2"></span>rive<span class="_ _5"> </span>conﬁdence<span class="_ _5"> </span>intervals<span class="_ _5"> </span>a<span class="_ _2"></span>nd<span class="_ _5"> </span>perform<span class="_ _5"> </span>hypothesis</div><div class="t m0 x21 h4 y19 ff3 fs2 fc0 sc0 ls0 ws0">tests<span class="_ _4"> </span>for<span class="_ _4"> </span>the<span class="_ _4"> </span>dependence<span class="_ _4"> </span>of<span class="_ _4"> </span>the<span class="_ _4"> </span>respons<span class="_ _9"></span>e<span class="_ _4"> </span>variable<span class="_ _4"> </span>on<span class="_ _4"> </span>the<span class="_ _4"> </span>independent<span class="_ _4"> </span>variables.<span class="_ _4"> </span>We</div><div class="t m0 x21 h4 y1a ff3 fs2 fc0 sc0 ls0 ws0">especially<span class="_ _6"> </span>emphasize<span class="_ _5"> </span>the<span class="_ _6"> </span>geometric<span class="_ _6"> </span>approach<span class="_ _5"> </span>to<span class="_ _6"> </span>evaluation.</div><div class="c x1c y2f w2 hc"><div class="t m1 x1d hd y30 ff9 fs4 fc0 sc0 ls0 ws0"><span class="fc2 sc0">For Online Reading </span><span class="fc2 sc0">Only</span></div></div><div class="c x1e y31 w3 he"><div class="t m0 x1f hf y32 ff9 fs5 fc1 sc0 ls0 ws0">This version is for online reading only. Unauthorized distribution is not allowed. </div><div class="t m0 x0 hf y33 ff9 fs5 fc1 sc0 ls0 ws0">Please cite the book if you find it useful, and leave a review on online platforms.<span class="fc2 sc0"> </span></div><div class="t m0 x20 hf y34 ff9 fs5 fc1 sc0 ls0 ws0">Please report all errata to contact@dataminingbook.info</div></div></div><div class="pi" data-data='{"ctm":[1.000000,0.000000,0.000000,1.000000,0.000000,0.000000]}'></div></div>
